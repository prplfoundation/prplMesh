variables:
  PYTHONUNBUFFERED: "1"

stages:
  - containers
  - build
  - test
  - certification-dummy
  - certification-netgear-rax40
  - certification-netgear-rax40-bhwifi
  - upload

.image-build:
  stage: containers
  tags:
    - shell
    - docker-build
  script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - if [ "$CI_COMMIT_BRANCH" = "master" ]; then latest_tag="--tag latest"; fi
    - ./tools/docker/image-build.sh --image "${CI_JOB_NAME#image-build-}" --tag $CI_PIPELINE_ID $latest_tag --push

image-build-runner:
  extends: .image-build

image-build-builder/alpine:
  extends: .image-build

image-build-builder/ubuntu/xenial:
  extends: .image-build

image-build-builder/ubuntu/bionic:
  extends: .image-build

image-build-tests-runner:
  extends: .image-build

.in-prplmesh-builder:
  image:
    name: $CI_REGISTRY_IMAGE/prplmesh-builder-ubuntu-bionic:$CI_PIPELINE_ID
    entrypoint: [""]
  tags:
    - docker
  needs: ["image-build-builder/ubuntu/bionic"]

cppcheck:
  stage: build
  image: $CI_REGISTRY_IMAGE/prplmesh-builder-alpine:$CI_PIPELINE_ID
  script:
    # cppcheck runs in the alpine image because every new release brings useful improvements
    # (the versions from Ubuntu get old too quickly)
    - tools/docker/static-analysis/cppcheck.sh common framework controller
  artifacts:
    paths:
      - cppcheck_results.txt
    when: always
  tags:
    - docker
  needs: ["image-build-builder/alpine"]

cppcheck-diff:
  stage: build
  image: $CI_REGISTRY_IMAGE/prplmesh-builder-alpine:$CI_PIPELINE_ID
  script:
    - ci/cppcheck/cppcheck-new-issues.sh
  artifacts:
    paths:
      - cppcheck_results.txt
      - cppcheck_existing_issues.txt
    expire_in: 4 weeks
    when: always
  tags:
    - docker
  needs: ["image-build-builder/alpine"]

flake8:
  stage: build
  image: pipelinecomponents/flake8:f087c4c
  script:
    - apk add --update --no-cache git
    - git ls-files -z -- '*.py' ':(exclude)tools/maptools.py' ':(exclude)framework/tlvf/tlvf.py' |
      xargs -0 -t flake8 --verbose
  needs: []

shellcheck:
  stage: build
  image: koalaman/shellcheck-alpine:v0.7.1
  before_script:
    - apk add --update --no-cache git
  script:
    - git ls-files -z '*.sh' '*.sh.in'  | xargs -0 shellcheck -x -P tools:ci/owncloud
  needs: []

clang-format:
  extends: .in-prplmesh-builder
  stage: build
  script:
    # Run clang-format and check there are no modified files
    - ./clang-format.sh
    # `diff-index` doesn't update the index so doesn't actually see changes. Need to manually update index.
    - git update-index -q --refresh
    # Use `diff-index` instead of `status` or `diff` because it gives more predictable output and exit code.
    - |
      git diff-index --exit-code HEAD || {
        ret=$?
        echo "Inconsistent formatting, please apply patch from artifacts"
        git diff > correct-formatting.patch
        exit $ret
      }
  artifacts:
    paths:
      - correct-formatting.patch
    when: on_failure

build-in-docker:
  extends: .in-prplmesh-builder
  stage: build
  variables:
    CMAKE_BUILD_TYPE: "Release"
    EXTRA_CMAKE_FLAGS: ""
  script:
    - cmake -DBUILD_TESTS=ON -DCMAKE_BUILD_TYPE=$CMAKE_BUILD_TYPE -DCMAKE_INSTALL_PREFIX=build/install \
      $EXTRA_CMAKE_FLAGS -H. -Bbuild -G Ninja
    - ninja -C build install
    # Check that the AutoGenerated files are correct by checking git status
    - git update-index -q --refresh
    - git diff-index --exit-code HEAD
  artifacts:
    paths:
      - build/install

build-in-docker-alpine:
  extends: build-in-docker
  image: $CI_REGISTRY_IMAGE/prplmesh-builder-alpine:$CI_PIPELINE_ID
  only:
    - schedules
  needs: ["image-build-builder/alpine"]

build-in-docker-ubuntu-xenial:
  extends: build-in-docker
  image: $CI_REGISTRY_IMAGE/prplmesh-builder-ubuntu-xenial:$CI_PIPELINE_ID
  needs: ["image-build-builder/ubuntu/xenial"]

build-in-docker-static:
  extends: build-in-docker
  variables:
    EXTRA_CMAKE_FLAGS: "-DBUILD_SHARED_LIBS=OFF"

upload-artifacts:
  stage: upload
  extends: .in-prplmesh-builder
  script:
    # the owncloud password is stored in the file pointed by "$CI_OWNCLOUD_PASSWORD".
    # We can only store the password in it, since spaces are not supported in Gitlab masked variables.
    # We symlink the file to .netrc and pre-pend to it to avoid manipulating the password itself
    # on the command line.
    - ln -s "$CI_OWNCLOUD_PASSWORD" ~/.netrc
    - sed --follow-symlinks -i 's/^/machine ftp.essensium.com login prplmesh-robot-ci password /' ~/.netrc
    - |
      echo "Updating the 'latest' folder"
      # Copying takes a lot of time, and we want the "latest" folder
      # to be updated "as fast as possible", so we rely on the script
      # to upload to a temporary directory first, and move it to
      # "latest" afterwards:
      ci/owncloud/upload_to_owncloud.sh -v "artifacts/latest" ./build
  rules:
    - if: '$CI_COMMIT_BRANCH == "master"'
      when: on_success
  needs:
    - build-in-docker
    - build-for-netgear-rax40
    - build-for-glinet-b1300
    - build-for-turris-omnia

.run-test-dctest:
  stage: test
  extends: .in-prplmesh-builder
  script:
    - ./dctest.py
  needs:
    - job: build-in-docker

.run-test-in-docker:
  stage: test
  extends: .in-prplmesh-builder
  script:
    - cd build/install
    - ./bin/tests/${CI_JOB_NAME}
  needs:
    - job: build-in-docker

tlvf_test:
  extends: .run-test-in-docker

bwl_dummy_unit_tests:
  extends: .run-test-in-docker

#bcl_unit_tests:
#  extends: .run-test-in-docker

# dctest_one_test:
#  extends: .run-test-dctest

# Replacing bcl_unit_tests to run dctest. XXX: This is a test; only for dev
# branch
bcl_unit_tests:
  extends: .run-test-dctest

run-tests:
  stage: test
  image: $CI_REGISTRY_IMAGE/prplmesh-tests-runner:$CI_PIPELINE_ID
  script:
    - tests/test_flows.py --verbose --unique-id $CI_JOB_ID --tag $CI_PIPELINE_ID

  artifacts:
    paths:
      - logs
    when: always

  tags:
    - docker
    - docker-build

  after_script:
    - tools/docker/stop.sh -k -r
  needs:
    - job: build-in-docker
    - job: image-build-tests-runner
    - job: image-build-runner

.build-for-openwrt:
  stage: build
  script:
    - mkdir -p "build/$TARGET_DEVICE"
    - tools/docker/builder/openwrt/build.sh --verbose -d "$TARGET_DEVICE" -t "prplmesh-builder-$TARGET_DEVICE:$CI_COMMIT_SHORT_SHA-$CI_PIPELINE_ID" 2>&1 | tee "build/$TARGET_DEVICE/openwrt-build.log" | grep -E '^[[:blank:]]?make\[[12]\]|^Step|^ --->' --color=never --line-buffered
  artifacts:
    paths:
      - "build/$TARGET_DEVICE/"
    expire_in: 4 weeks
    when: always
  tags:
    - shell
    - docker-build
  needs: []

.test-on-target:
  stage: test
  before_script:
    # we need a list of all the targets to be able to kill them
    - ALL_TARGETS="turris-omnia-1 glinet-b1300-1 netgear-rax40-1"
    # kill prplmesh on each target to make sure they don't interfere with the test
    - for i in $ALL_TARGETS ; do ssh "$i" 'pgrep -f beerocks | xargs kill -9 2>/dev/null' || true ; done
  script:
    - tools/deploy_firmware.py --device "$TARGET_DEVICE" --target-name "$TARGET_DEVICE_NAME" --image "$OPENWRT_IMAGE"
    - tools/deploy_ipk.sh $TARGET_DEVICE_NAME "build/$TARGET_DEVICE/"prplmesh.ipk
    - tests/openwrt/test_status.sh $TARGET_DEVICE_NAME
  artifacts:
    paths:
      - logs
    expire_in: 4 weeks
    when: always
  tags:
    - targets
  timeout: 20m

build-for-turris-omnia:
  extends: .build-for-openwrt
  variables:
    TARGET_DEVICE: "turris-omnia"

build-for-glinet-b1300:
  extends: .build-for-openwrt
  variables:
    TARGET_DEVICE: "glinet-b1300"

build-for-netgear-rax40:
  extends: .build-for-openwrt
  variables:
    TARGET_DEVICE: "netgear-rax40"

test-on-turris-omnia:
  extends: .test-on-target
  variables:
    TARGET_DEVICE: turris-omnia
    TARGET_DEVICE_NAME: turris-omnia-1
    OPENWRT_IMAGE: openwrt-mvebu-cortexa9-cznic_turris-omnia-sysupgrade.img.gz
  needs: ["build-for-turris-omnia"]

test-on-glinet-b1300:
  extends: .test-on-target
  variables:
    TARGET_DEVICE: glinet-b1300
    TARGET_DEVICE_NAME: glinet-b1300-1
    OPENWRT_IMAGE: openwrt-ipq40xx-generic-glinet_gl-b1300-squashfs-sysupgrade.bin
  needs: ["build-for-glinet-b1300"]

test-on-netgear-rax40:
  extends: .test-on-target
  variables:
    TARGET_DEVICE: netgear-rax40
    TARGET_DEVICE_NAME: netgear-rax40-1
    OPENWRT_IMAGE: NETGEAR_RAX40-squashfs-fullimage.img
  needs: ["build-for-netgear-rax40"]

run-certification-tests:
  stage: test
  variables:
    # TESTS_TO_RUN needs to be set by the user (or the pipeline schedule)
    GIT_CLONE_PATH: "/builds/prpl-foundation/prplMesh/"
    # device to test with: prplmesh for dummy bwl, netgear-rax40 for dwpal on rax40
    DEVICE_UNDER_TEST: prplmesh
  script:
    - |
      if [ "$DEVICE_UNDER_TEST" = netgear-rax40 ] ; then
          tools/deploy_firmware.py --device netgear-rax40 --target-name "$DEVICE_UNDER_TEST" --image NETGEAR_RAX40-squashfs-fullimage.img
          echo "Deploying to $DEVICE_UNDER_TEST"
          tools/deploy_ipk.sh --certification-mode $DEVICE_UNDER_TEST build/$DEVICE_UNDER_TEST/prplmesh.ipk
      fi
    - sudo /easymesh_cert/run_test_file.py --upload-results  --verbose --log-folder logs --device-under-test $DEVICE_UNDER_TEST $TESTS_TO_RUN
  artifacts:
    paths:
      - logs
    when: always
  needs:
    - job: build-in-docker
    - job: build-for-netgear-rax40
  tags:
    - certs-tests
  timeout: 36h
  rules:
    - if: "$TESTS_TO_RUN"

include:
  - local: "/ci/certification/generic.yml"
  - local: "/ci/certification/dummy.yml"
  - local: "/ci/certification/netgear-rax40.yml"
  - local: "/ci/certification/netgear-rax40-bhwifi.yml"
